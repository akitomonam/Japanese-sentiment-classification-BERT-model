{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 発話感情分類モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './data'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
      "remote: Total 58 (delta 20), reused 48 (delta 13), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (58/58), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ids-cv/wrime.git ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-30 13:46:41--  https://www.dropbox.com/s/rkzyeu58p48ndz3/japanese_empathetic_dialogues.xlsx?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6030:18::a27d:5012\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/rkzyeu58p48ndz3/japanese_empathetic_dialogues.xlsx [following]\n",
      "--2022-07-30 13:46:41--  https://www.dropbox.com/s/raw/rkzyeu58p48ndz3/japanese_empathetic_dialogues.xlsx\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com/cd/0/inline/BqADomMflA4HHssZEsC-sGMG6jfxVyO9UNr1SCBWJVaCuYuR-9kjj_PSliNBa4r-0tTJ-KaJ3rDFr-3ffzoieiJj4b63fhYQ16JVs8bELUoqKnotBcA0Cka-_5_XKtp8NYPzYQzdClaIKd8OkwyIfWHMphmGvzztKZiTQ0q_MzPDFA/file# [following]\n",
      "--2022-07-30 13:46:42--  https://uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com/cd/0/inline/BqADomMflA4HHssZEsC-sGMG6jfxVyO9UNr1SCBWJVaCuYuR-9kjj_PSliNBa4r-0tTJ-KaJ3rDFr-3ffzoieiJj4b63fhYQ16JVs8bELUoqKnotBcA0Cka-_5_XKtp8NYPzYQzdClaIKd8OkwyIfWHMphmGvzztKZiTQ0q_MzPDFA/file\n",
      "Resolving uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com (uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6030:15::a27d:500f\n",
      "Connecting to uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com (uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/BqBCQTe2cDO6otDmsVrwqBoE7oKTzk5495cbyu30gMc3NUfbyRWpwtGK_1uSHkIYw-7CGc65ejKg3r0juA7ZXOoqrTy88wcVJvtGkHt7oaZnEKXvCwXprkKEjfVKtd4C4QAPk-7GFQPhpIrB0FBPu4ygQOKNxgnwDvV6WGjAoTAueuPd3T5r6Ff5GwiWDO35aKdDX0PAJDdbYskYLW0-HzfrDUM1ZZxeqOTNKYmiiwf5McXbilGQzLKK1fSHw07Hzn-PgO1gKycKLQtetD2033AQ3G-0cxIuXMJ-CCpvV8RJvRlLmvOi_eKbD2ADuiF9jP7BiufqPHVUOA0_11m980rLXoECOqbvqjZXz76GqaIjAlhweQUIlj4SlepPwyqCg4XtkIARJEZ-lQmTZQGOubZsmFdlASEVu81TgNL1GjkieA/file [following]\n",
      "--2022-07-30 13:46:42--  https://uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com/cd/0/inline2/BqBCQTe2cDO6otDmsVrwqBoE7oKTzk5495cbyu30gMc3NUfbyRWpwtGK_1uSHkIYw-7CGc65ejKg3r0juA7ZXOoqrTy88wcVJvtGkHt7oaZnEKXvCwXprkKEjfVKtd4C4QAPk-7GFQPhpIrB0FBPu4ygQOKNxgnwDvV6WGjAoTAueuPd3T5r6Ff5GwiWDO35aKdDX0PAJDdbYskYLW0-HzfrDUM1ZZxeqOTNKYmiiwf5McXbilGQzLKK1fSHw07Hzn-PgO1gKycKLQtetD2033AQ3G-0cxIuXMJ-CCpvV8RJvRlLmvOi_eKbD2ADuiF9jP7BiufqPHVUOA0_11m980rLXoECOqbvqjZXz76GqaIjAlhweQUIlj4SlepPwyqCg4XtkIARJEZ-lQmTZQGOubZsmFdlASEVu81TgNL1GjkieA/file\n",
      "Reusing existing connection to uc78834bc3210eccf23b02adc924.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4885866 (4.7M) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
      "Saving to: ‘./data/japanese_empathetic_dialogues.xlsx’\n",
      "\n",
      "apanese_empathetic_ 100%[===================>]   4.66M  26.0MB/s    in 0.2s    \n",
      "\n",
      "2022-07-30 13:46:43 (26.0 MB/s) - ‘./data/japanese_empathetic_dialogues.xlsx’ saved [4885866/4885866]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ./data/japanese_empathetic_dialogues.xlsx -P content  https://www.dropbox.com/s/rkzyeu58p48ndz3/japanese_empathetic_dialogues.xlsx?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## japanese_empathetic_dialogues前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_env = pd.read_excel(\"./data/japanese_empathetic_dialogues.xlsx\",sheet_name=\"状況文\")\n",
    "df_env = df_env.rename(columns={'作業No':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utt = pd.read_excel(\"./data/japanese_empathetic_dialogues.xlsx\",sheet_name=\"対話\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_utt, df_env, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['おどろく' 'わくわくする' '怒る' '誇りに思う' '悲しい' 'いらいらする' '感謝する' 'さびしい' '怖い' '恐ろしい'\n",
      " 'うしろめたい' '感動する' '嫌悪感を抱く' '期待する' '自信がある' '激怒する' '不安に思う' '待ち望む' '楽しい'\n",
      " '懐かしい' 'がっかりする' '心構えする' '羨ましい' '満足' '打ちのめされる' '恥ずかしい' '思いやりを持つ' '感傷的になる'\n",
      " '信頼する' '恥じる' '懸念する' '誠実な気持ち']\n",
      "32\n",
      "おどろく       2500\n",
      "わくわくする     2500\n",
      "懸念する       2500\n",
      "恥じる        2500\n",
      "信頼する       2500\n",
      "感傷的になる     2500\n",
      "思いやりを持つ    2500\n",
      "恥ずかしい      2500\n",
      "打ちのめされる    2500\n",
      "満足         2500\n",
      "羨ましい       2500\n",
      "心構えする      2500\n",
      "がっかりする     2500\n",
      "懐かしい       2500\n",
      "楽しい        2500\n",
      "待ち望む       2500\n",
      "不安に思う      2500\n",
      "激怒する       2500\n",
      "自信がある      2500\n",
      "期待する       2500\n",
      "嫌悪感を抱く     2500\n",
      "感動する       2500\n",
      "うしろめたい     2500\n",
      "恐ろしい       2500\n",
      "怖い         2500\n",
      "さびしい       2500\n",
      "感謝する       2500\n",
      "いらいらする     2500\n",
      "悲しい        2500\n",
      "誇りに思う      2500\n",
      "怒る         2500\n",
      "誠実な気持ち     2500\n",
      "Name: 感情, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "empathtic_names = df[\"感情\"].unique()\n",
    "print(empathtic_names)\n",
    "print(len(empathtic_names))\n",
    "print(df[\"感情\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 話者がAだけ残す\n",
    "df = df[df[\"話者\"] == \"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発話</th>\n",
       "      <th>感情</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>今日ズボンのチャックが開いたまま大勢の前でスピーチをして、恥ずかしい思いをしたよ。</td>\n",
       "      <td>恥ずかしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>スピーチのことに集中していたから気づかなかったんだよ。</td>\n",
       "      <td>恥ずかしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>今朝混んでる電車に息切れをしたおじいさんが乗ってきたから席を譲ったんだ。</td>\n",
       "      <td>思いやりを持つ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>勇気を出して声をかけたら感謝をされたよ。</td>\n",
       "      <td>思いやりを持つ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>若いうちに親を亡くした子供の映画を見て感傷的になった。</td>\n",
       "      <td>感傷的になる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>今回の映画は主人公の描写が繊細でグッとくるものがあったよ。</td>\n",
       "      <td>感傷的になる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>今度の大きなプロジェクト、賢くて才能のある若手に任せることにしました。</td>\n",
       "      <td>信頼する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>色々な事を知っているし、落ち着いて冷静な判断もできる信頼しがいのある男です。</td>\n",
       "      <td>信頼する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>この間雑談中に知ったかぶりしているのがバレちゃった。</td>\n",
       "      <td>恥じる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>顔に全部出ていてみんなお見通しだったって言っていた。</td>\n",
       "      <td>恥じる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ニュース見た？大型の台風来てるんだって。</td>\n",
       "      <td>懸念する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ルートには入ってる。十年に一度の大型台風らしいし、逸れれば良いんだけれど。</td>\n",
       "      <td>懸念する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>仕事でクライアントを怒らせてしまいました。反省することばかりですね。</td>\n",
       "      <td>誠実な気持ち</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ええ、私の伝え方が悪くて意思疎通の齟齬が出てしまって。もっと精進しなければと思っています。</td>\n",
       "      <td>誠実な気持ち</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>そういえば聞いた？あの子プロポーズされたらしいよ。</td>\n",
       "      <td>おどろく</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>そうなの。すごくビックリしてる。全然知らなかったからさ。</td>\n",
       "      <td>おどろく</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>今度ついにあの関東のテーマパーク行くんだ。</td>\n",
       "      <td>わくわくする</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>実は一回もないんだよね。だから今からその日が待ち遠しいよ。</td>\n",
       "      <td>わくわくする</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ホント腹立つ。このあいだ不良品掴まされたんだよね。</td>\n",
       "      <td>怒る</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>したけど、無理だった。レシート捨てちゃってたからさ。お金無駄になった。</td>\n",
       "      <td>怒る</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>子どもが夏休みに書いた読書感想文、大賞とっちゃったの。</td>\n",
       "      <td>誇りに思う</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>私から見ても確かに良く書けてたと思う。私の自慢の息子だよ。</td>\n",
       "      <td>誇りに思う</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>飼ってた犬、ついに死んじゃった。</td>\n",
       "      <td>悲しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>前に撮った写真見返すと泣けてきちゃって。まだ引きずってる。</td>\n",
       "      <td>悲しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>いつも子どもが部屋を滅茶苦茶にするから部屋が片付かない。</td>\n",
       "      <td>いらいらする</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>そうなの。片付けても一瞬で散らかっちゃう。</td>\n",
       "      <td>いらいらする</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>財布落としちゃったんだけど、戻ってきて良かったよ。</td>\n",
       "      <td>感謝する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>交番に届いてた。そのまま届けてくれた人にありがとうって言いたいよ。</td>\n",
       "      <td>感謝する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>親友が転校しちゃうんだ。もう簡単に会えなくなるのかあ。</td>\n",
       "      <td>さびしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>来月。毎日学校で会って遊んでたからね。</td>\n",
       "      <td>さびしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>昨日、雨降ったよね。</td>\n",
       "      <td>怖い</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>雷も鳴ってとっても怖かったよ。</td>\n",
       "      <td>怖い</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>暗い道を歩いていたら、物音が聞こえて恐ろしかったよ。</td>\n",
       "      <td>恐ろしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>黒い猫が飛び出してきたの。</td>\n",
       "      <td>恐ろしい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>友達との約束の日にどうしても行きたいライブがあって。</td>\n",
       "      <td>うしろめたい</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                発話       感情\n",
       "100      今日ズボンのチャックが開いたまま大勢の前でスピーチをして、恥ずかしい思いをしたよ。    恥ずかしい\n",
       "102                    スピーチのことに集中していたから気づかなかったんだよ。    恥ずかしい\n",
       "104           今朝混んでる電車に息切れをしたおじいさんが乗ってきたから席を譲ったんだ。  思いやりを持つ\n",
       "106                           勇気を出して声をかけたら感謝をされたよ。  思いやりを持つ\n",
       "108                    若いうちに親を亡くした子供の映画を見て感傷的になった。   感傷的になる\n",
       "110                  今回の映画は主人公の描写が繊細でグッとくるものがあったよ。   感傷的になる\n",
       "112            今度の大きなプロジェクト、賢くて才能のある若手に任せることにしました。     信頼する\n",
       "114         色々な事を知っているし、落ち着いて冷静な判断もできる信頼しがいのある男です。     信頼する\n",
       "116                     この間雑談中に知ったかぶりしているのがバレちゃった。      恥じる\n",
       "118                     顔に全部出ていてみんなお見通しだったって言っていた。      恥じる\n",
       "120                           ニュース見た？大型の台風来てるんだって。     懸念する\n",
       "122          ルートには入ってる。十年に一度の大型台風らしいし、逸れれば良いんだけれど。     懸念する\n",
       "124             仕事でクライアントを怒らせてしまいました。反省することばかりですね。   誠実な気持ち\n",
       "126  ええ、私の伝え方が悪くて意思疎通の齟齬が出てしまって。もっと精進しなければと思っています。   誠実な気持ち\n",
       "128                      そういえば聞いた？あの子プロポーズされたらしいよ。     おどろく\n",
       "130                   そうなの。すごくビックリしてる。全然知らなかったからさ。     おどろく\n",
       "132                          今度ついにあの関東のテーマパーク行くんだ。   わくわくする\n",
       "134                  実は一回もないんだよね。だから今からその日が待ち遠しいよ。   わくわくする\n",
       "136                      ホント腹立つ。このあいだ不良品掴まされたんだよね。       怒る\n",
       "138            したけど、無理だった。レシート捨てちゃってたからさ。お金無駄になった。       怒る\n",
       "140                    子どもが夏休みに書いた読書感想文、大賞とっちゃったの。    誇りに思う\n",
       "142                  私から見ても確かに良く書けてたと思う。私の自慢の息子だよ。    誇りに思う\n",
       "144                               飼ってた犬、ついに死んじゃった。      悲しい\n",
       "146                  前に撮った写真見返すと泣けてきちゃって。まだ引きずってる。      悲しい\n",
       "148                   いつも子どもが部屋を滅茶苦茶にするから部屋が片付かない。   いらいらする\n",
       "150                          そうなの。片付けても一瞬で散らかっちゃう。   いらいらする\n",
       "152                      財布落としちゃったんだけど、戻ってきて良かったよ。     感謝する\n",
       "154              交番に届いてた。そのまま届けてくれた人にありがとうって言いたいよ。     感謝する\n",
       "156                    親友が転校しちゃうんだ。もう簡単に会えなくなるのかあ。     さびしい\n",
       "158                            来月。毎日学校で会って遊んでたからね。     さびしい\n",
       "160                                     昨日、雨降ったよね。       怖い\n",
       "162                                雷も鳴ってとっても怖かったよ。       怖い\n",
       "164                     暗い道を歩いていたら、物音が聞こえて恐ろしかったよ。     恐ろしい\n",
       "166                                  黒い猫が飛び出してきたの。     恐ろしい\n",
       "168                     友達との約束の日にどうしても行きたいライブがあって。   うしろめたい"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"ID\", \"話者\", \"状況文\"], axis=1,inplace=True)\n",
    "df = df.reindex(columns=['発話','感情'])\n",
    "df[50:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32個の感情を8個にまとめる\n",
    "emotions_dict = {\n",
    "    \"喜び\":[\"感謝する\",\"感動する\",\"楽しい\",\"満足\"],\n",
    "    \"悲しみ\":[\"悲しい\",\"さびしい\",\"がっかりする\",\"打ちのめされる\",\"感傷的になる\"],\n",
    "    \"期待\":[\"わくわくする\",\"期待する\",\"待ち望む\"],\n",
    "    \"驚き\":[\"おどろく\"],\n",
    "    \"怒り\":[\"怒る\",\"いらいらする\",\"激怒する\"],\n",
    "    \"恐れ\":[\"怖い\",\"恐ろしい\",\"不安に思う\",\"懸念する\"],\n",
    "    \"嫌悪\":[\"うしろめたい\",\"嫌悪感を抱く\",\"恥ずかしい\",\"恥じる\"],\n",
    "    \"信頼\":[\"自信がある\",\"信頼する\",\"誠実な気持ち\"]\n",
    "}\n",
    "drop_emotions = [\"誇りに思う\",\"心構えする\",\"羨ましい\",\"懐かしい\",\"思いやりを持つ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_emo, c_emos in emotions_dict.items():\n",
    "    df[\"感情\"].replace(c_emos,p_emo,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用しない感情の行を削除する\n",
    "for emo in drop_emotions:\n",
    "    df = df[df[\"感情\"] != emo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['驚き' '期待' '怒り' '悲しみ' '喜び' '恐れ' '嫌悪' '信頼']\n",
      "8\n",
      "悲しみ    6250\n",
      "喜び     5000\n",
      "恐れ     5000\n",
      "嫌悪     5000\n",
      "期待     3750\n",
      "怒り     3750\n",
      "信頼     3750\n",
      "驚き     1250\n",
      "Name: 感情, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "empathtic_names = df[\"感情\"].unique()\n",
    "print(empathtic_names)\n",
    "print(len(empathtic_names))\n",
    "print(df[\"感情\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRIME前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrime = pd.read_csv('./data/wrime-ver2.tsv', delimiter='\\t')\n",
    "# 必要な列だけ抽出\n",
    "df_wrime = df_wrime.loc[:,[\"Sentence\",\"Train/Dev/Test\",\n",
    "\"Writer_Joy\",\"Writer_Sadness\",\"Writer_Anticipation\",\"Writer_Surprise\",\"Writer_Anger\",\"Writer_Fear\",\"Writer_Disgust\",\"Writer_Trust\",\"Writer_Sentiment\",\n",
    "\"Avg. Readers_Joy\",\"Avg. Readers_Sadness\",\"Avg. Readers_Anticipation\",\"Avg. Readers_Surprise\",\"Avg. Readers_Anger\",\"Avg. Readers_Fear\",\n",
    "\"Avg. Readers_Disgust\",\"Avg. Readers_Trust\",\"Avg. Readers_Sentiment\"]]\n",
    "len(df_wrime.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2人のアノテーターの合計の多数決で感情を決定\n",
    "# df_wrime.isnull().sum()\n",
    "add_emotion_dict = {\n",
    "    \"喜び\":[\"Writer_Joy\", \"Avg. Readers_Joy\"],\n",
    "    \"悲しみ\":[\"Writer_Sadness\",\"Avg. Readers_Sadness\"],\n",
    "    \"期待\":[\"Writer_Anticipation\",\"Avg. Readers_Anticipation\"],\n",
    "    \"驚き\":[\"Writer_Surprise\",\"Avg. Readers_Surprise\"],\n",
    "    \"怒り\":[\"Writer_Anger\",\"Avg. Readers_Anger\"],\n",
    "    \"恐れ\":[\"Writer_Fear\",\"Avg. Readers_Fear\"],\n",
    "    \"嫌悪\":[\"Writer_Disgust\",\"Avg. Readers_Disgust\"],\n",
    "    \"信頼\":[\"Writer_Trust\",\"Avg. Readers_Trust\"]\n",
    "    # \"Sentiment\":[\"Writer_Sentiment\",\"Avg. Readers_Sentiment\"] （今回は感情極性を使わない）\n",
    "}\n",
    "\n",
    "# それぞれの感情で合計値を計算\n",
    "for emo_p, emo_c_list in add_emotion_dict.items():\n",
    "    df_wrime = pd.concat([df_wrime, pd.DataFrame(df_wrime.loc[:,emo_c_list].sum(axis=1), columns=[emo_p])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrime = df_wrime.loc[:, [\"Sentence\"] + list(add_emotion_dict.keys())] # 必要な列だけ抽出\n",
    "df_wrime.rename(columns={\"Sentence\":\"発話\"}, inplace=True) # 列名変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 感情ラベルを数値で多数決してラベルを決定\n",
    "df_wrime = pd.concat([df_wrime, pd.DataFrame(df_wrime.loc[:, list(add_emotion_dict.keys())].idxmax(axis=1), columns=[\"感情\"])], axis=1) # 各感情で一番大きい感情を取り出し新しく感情ラベル列を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発話</th>\n",
       "      <th>感情</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。</td>\n",
       "      <td>驚き</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>眠い、眠れない。</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>真夜中にふと思い立ち、ノートPCを持って部屋を出て、ダイニングで仕事したらすんごい捗った。\\...</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>ぐっどこんでぃしょん。\\n心も頭もクリア。\\n秋分の日のおかげかな？\\n人と自然としっとり過...</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>朝から免許の更新へ。\\n90分で終わり、出口へ向かうと献血の呼びかけが。\\nみんな通り過ぎて...</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>夜も更けて参りましたが、食後のコーヒーが飲みたいのでドリップ開始…\\n\\nぼんやり秋の夜長を...</td>\n",
       "      <td>期待</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>コーヒー休憩（kahavitauko）\\n\\nいつもの豆なのにすごく美味しくできた \\n\\n...</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      発話   感情\n",
       "0                         ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…  悲しみ\n",
       "1      今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...   喜び\n",
       "2                     早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。   驚き\n",
       "3                                               眠い、眠れない。  悲しみ\n",
       "4        ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!   喜び\n",
       "...                                                  ...  ...\n",
       "34995  真夜中にふと思い立ち、ノートPCを持って部屋を出て、ダイニングで仕事したらすんごい捗った。\\...   喜び\n",
       "34996  ぐっどこんでぃしょん。\\n心も頭もクリア。\\n秋分の日のおかげかな？\\n人と自然としっとり過...   喜び\n",
       "34997  朝から免許の更新へ。\\n90分で終わり、出口へ向かうと献血の呼びかけが。\\nみんな通り過ぎて...   喜び\n",
       "34998  夜も更けて参りましたが、食後のコーヒーが飲みたいのでドリップ開始…\\n\\nぼんやり秋の夜長を...   期待\n",
       "34999  コーヒー休憩（kahavitauko）\\n\\nいつもの豆なのにすごく美味しくできた \\n\\n...   喜び\n",
       "\n",
       "[35000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrime = df_wrime.loc[:, [\"発話\",\"感情\"]] # 使用する列だけ抽出\n",
    "df_wrime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "喜び     10095\n",
      "悲しみ     8528\n",
      "期待      6926\n",
      "驚き      4046\n",
      "恐れ      2225\n",
      "嫌悪      1911\n",
      "怒り       830\n",
      "信頼       439\n",
      "Name: 感情, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df_wrime[\"感情\"].unique()))\n",
    "print(df_wrime[\"感情\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データフレームの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33750\n",
      "35000\n",
      "68750\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_wrime))\n",
    "df = pd.concat([df, df_wrime], axis=0)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " # シャッフルする\n",
    "df = df.sample(frac=1, random_state=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "喜び     15095\n",
      "悲しみ    14778\n",
      "期待     10676\n",
      "恐れ      7225\n",
      "嫌悪      6911\n",
      "驚き      5296\n",
      "怒り      4580\n",
      "信頼      4189\n",
      "Name: 感情, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"感情\"].unique()))\n",
    "print(df[\"感情\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発話</th>\n",
       "      <th>感情</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>いや、さすがにみんな立ち回り下手すぎた笑</td>\n",
       "      <td>驚き</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>昨日と同じ場所にねこちゃんがいてくれるのうれしいよなぁ</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37828</th>\n",
       "      <td>こんな調子で将来どうやって生きていくの？⇒心配しなくてもその将来が来る前に黒い染みになります</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13201</th>\n",
       "      <td>ふっじっさーん ふっじっさーん゛゛</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63145</th>\n",
       "      <td>何も悪いことをしていないのに、とんでもない話です。</td>\n",
       "      <td>怒り</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32078</th>\n",
       "      <td>わたしの家の前は広場になっているんですが、そこでいつも立ち話をするおばさんがいます。</td>\n",
       "      <td>怒り</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49852</th>\n",
       "      <td>バス間に合ったーパフェでそう</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55121</th>\n",
       "      <td>3日くらい前にスピループスでペンを買ったんだが、ログインせずに情報だけ打ち込んだせいなのかメ...</td>\n",
       "      <td>恐れ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>さあもうすぐ沢山のリア充が乗り込んで来るぞ！皆覚悟はよいか!?</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51897</th>\n",
       "      <td>隣の方、相席良いですか？って一言いうか机離すかせめて反対側に座るか何か出来ませんか？\\nなぜ...</td>\n",
       "      <td>驚き</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      発話   感情\n",
       "17181                               いや、さすがにみんな立ち回り下手すぎた笑   驚き\n",
       "8297                         昨日と同じ場所にねこちゃんがいてくれるのうれしいよなぁ   喜び\n",
       "37828     こんな調子で将来どうやって生きていくの？⇒心配しなくてもその将来が来る前に黒い染みになります  悲しみ\n",
       "13201                                  ふっじっさーん ふっじっさーん゛゛   喜び\n",
       "63145                          何も悪いことをしていないのに、とんでもない話です。   怒り\n",
       "...                                                  ...  ...\n",
       "32078         わたしの家の前は広場になっているんですが、そこでいつも立ち話をするおばさんがいます。   怒り\n",
       "49852                                     バス間に合ったーパフェでそう   喜び\n",
       "55121  3日くらい前にスピループスでペンを買ったんだが、ログインせずに情報だけ打ち込んだせいなのかメ...   恐れ\n",
       "18376                    さあもうすぐ沢山のリア充が乗り込んで来るぞ！皆覚悟はよいか!?  悲しみ\n",
       "51897  隣の方、相席良いですか？って一言いうか机離すかせめて反対側に座るか何か出来ませんか？\\nなぜ...   驚き\n",
       "\n",
       "[68750 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発話テキスト前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # 「]の削除\n",
    "    text = text.replace('「','')\n",
    "    text = text.replace('」','')\n",
    "    # URLの削除\n",
    "    text = re.sub(r'http?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', text)\n",
    "    text = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', text)\n",
    "    # pic.twitter.comXXXの削除\n",
    "    text = re.sub(r'pic.twitter.com/[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', text)\n",
    "    # 全角記号削除\n",
    "    text = re.sub(\"[\\uFF01-\\uFF0F\\uFF1A-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\u3000-\\u303F]\", '', text)\n",
    "    # 半角記号の置換\n",
    "    text = re.sub(r'[!-/:-@[-`{-~]', r' ', text)\n",
    "    # 全角記号の置換 (ここでは0x25A0 - 0x266Fのブロックのみを除去)\n",
    "    text = re.sub(u'[■-♯]', ' ', text)\n",
    "    # 数値をすべて0に変換\n",
    "    text = re.sub(r'\\d+', '0', text)\n",
    "    text = text.replace(\"\\n\",\"\")\n",
    "    text = text.replace(\"。\",\"\")\n",
    "    text = text.replace(\".\",\"\")\n",
    "    text = text.replace(\",\",\"\")\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"発話\"] = df[\"発話\"].map(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発話</th>\n",
       "      <th>感情</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>最近のホロライブは内部コラボを重視してる前ほど外部コラボはなくなった</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51852</th>\n",
       "      <td>昼暑くて朝寒いし朝明るくて夜暗いし夜寝たくなくて昼眠いし繰り返してばっかかよ</td>\n",
       "      <td>悲しみ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47291</th>\n",
       "      <td>いろんな経験をしてきたんやな</td>\n",
       "      <td>驚き</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>ラジオ聴く環境作らなくなったし校長教頭変わってからほっとんど聴いてない奴いうのもアレなんだけ...</td>\n",
       "      <td>信頼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34026</th>\n",
       "      <td>そうなんですよ気になり出すとずっと気になっちゃって</td>\n",
       "      <td>怒り</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23823</th>\n",
       "      <td>今0歳保育園でみんなで描いたみたいよ</td>\n",
       "      <td>喜び</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43365</th>\n",
       "      <td>茶色いとか煮物が嫌だとか母に文句を言っていた昔の自分が恥ずかしい</td>\n",
       "      <td>嫌悪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43620</th>\n",
       "      <td>バーゲンだから買い物してくるよ</td>\n",
       "      <td>期待</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41359</th>\n",
       "      <td>本当に怖いよねこれからどうなってくか不安</td>\n",
       "      <td>恐れ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48730</th>\n",
       "      <td>気付かずに賞味期限切れの羊羹をお客に出してしまいました</td>\n",
       "      <td>嫌悪</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      発話   感情\n",
       "3481                  最近のホロライブは内部コラボを重視してる前ほど外部コラボはなくなった  悲しみ\n",
       "51852             昼暑くて朝寒いし朝明るくて夜暗いし夜寝たくなくて昼眠いし繰り返してばっかかよ  悲しみ\n",
       "47291                                     いろんな経験をしてきたんやな   驚き\n",
       "3171   ラジオ聴く環境作らなくなったし校長教頭変わってからほっとんど聴いてない奴いうのもアレなんだけ...   信頼\n",
       "34026                          そうなんですよ気になり出すとずっと気になっちゃって   怒り\n",
       "...                                                  ...  ...\n",
       "23823                                 今0歳保育園でみんなで描いたみたいよ   喜び\n",
       "43365                   茶色いとか煮物が嫌だとか母に文句を言っていた昔の自分が恥ずかしい   嫌悪\n",
       "43620                                    バーゲンだから買い物してくるよ   期待\n",
       "41359                               本当に怖いよねこれからどうなってくか不安   恐れ\n",
       "48730                        気付かずに賞味期限切れの羊羹をお客に出してしまいました   嫌悪\n",
       "\n",
       "[68750 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'感情':'label'})\n",
    "df = df.rename(columns={'発話':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51562\n",
      "4    0.219561\n",
      "3    0.214945\n",
      "1    0.155289\n",
      "5    0.105097\n",
      "6    0.100520\n",
      "0    0.077033\n",
      "2    0.066619\n",
      "7    0.060936\n",
      "Name: label, dtype: float64\n",
      "17188\n",
      "4    0.219572\n",
      "3    0.214976\n",
      "1    0.155283\n",
      "5    0.105073\n",
      "6    0.100535\n",
      "0    0.077030\n",
      "2    0.066616\n",
      "7    0.060915\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, random_state=111, stratify=df.label) # 訓練用とテスト用に分割 defalut 25%がテストデータ\n",
    "print(len(data_train))\n",
    "print(data_train[\"label\"].value_counts() /  len(data_train))\n",
    "print(len(data_test))\n",
    "print(data_test[\"label\"].value_counts() / len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51562"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = data_train[\"text\"].tolist()\n",
    "train_labels = data_train[\"label\"].tolist()\n",
    "len(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17188"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = data_test[\"text\"].tolist()\n",
    "test_labels = data_test[\"label\"].tolist()\n",
    "len(test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU が利用できる場合は GPU を利用する\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 517/517 [00:00<00:00, 197kB/s]\n",
      "Downloading: 100%|██████████| 427M/427M [00:05<00:00, 78.6MB/s] \n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 230k/230k [00:00<00:00, 356kB/s]  \n",
      "Downloading: 100%|██████████| 174/174 [00:00<00:00, 82.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,BertJapaneseTokenizer\n",
    "from transformers import AdamW\n",
    "\n",
    "sc_model = BertForSequenceClassification.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\", num_labels=len(empathtic_names))\n",
    "model = sc_model.to(device)\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エンコーディング\n",
    "Transformerモデルの入力としてはテンソル形式に変換する必要がある。\n",
    "返り値のテンソルのタイプを選ぶことができる。ここではPyTorchのテンソル型で返してくれるよう、return_tensors='pt'としている。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_docs, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
    "test_encodings = tokenizer(test_docs, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class JpSentiDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = JpSentiDataset(train_encodings, train_labels)\n",
    "test_dataset = JpSentiDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価関数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JEmpatheticDialogues_WRIME.ipynb  data\tdocker_env  logs\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./logs\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 51562\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12892\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12892' max='12892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12892/12892 2:22:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.084600</td>\n",
       "      <td>2.010182</td>\n",
       "      <td>0.186060</td>\n",
       "      <td>0.140976</td>\n",
       "      <td>0.151905</td>\n",
       "      <td>0.186060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.982100</td>\n",
       "      <td>1.913849</td>\n",
       "      <td>0.260182</td>\n",
       "      <td>0.157552</td>\n",
       "      <td>0.194930</td>\n",
       "      <td>0.260182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.872600</td>\n",
       "      <td>1.776684</td>\n",
       "      <td>0.358273</td>\n",
       "      <td>0.275931</td>\n",
       "      <td>0.267133</td>\n",
       "      <td>0.358273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.755200</td>\n",
       "      <td>1.643520</td>\n",
       "      <td>0.409239</td>\n",
       "      <td>0.341711</td>\n",
       "      <td>0.483181</td>\n",
       "      <td>0.409239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.580500</td>\n",
       "      <td>1.561088</td>\n",
       "      <td>0.438213</td>\n",
       "      <td>0.401521</td>\n",
       "      <td>0.447354</td>\n",
       "      <td>0.438213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.562100</td>\n",
       "      <td>1.459406</td>\n",
       "      <td>0.489993</td>\n",
       "      <td>0.464146</td>\n",
       "      <td>0.521146</td>\n",
       "      <td>0.489993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.531000</td>\n",
       "      <td>1.413880</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.535284</td>\n",
       "      <td>0.505178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.463700</td>\n",
       "      <td>1.428174</td>\n",
       "      <td>0.508843</td>\n",
       "      <td>0.488556</td>\n",
       "      <td>0.540471</td>\n",
       "      <td>0.508843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.418800</td>\n",
       "      <td>1.418743</td>\n",
       "      <td>0.504189</td>\n",
       "      <td>0.492892</td>\n",
       "      <td>0.559356</td>\n",
       "      <td>0.504189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.365600</td>\n",
       "      <td>1.392136</td>\n",
       "      <td>0.515418</td>\n",
       "      <td>0.510849</td>\n",
       "      <td>0.533314</td>\n",
       "      <td>0.515418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.430600</td>\n",
       "      <td>1.359862</td>\n",
       "      <td>0.531999</td>\n",
       "      <td>0.522378</td>\n",
       "      <td>0.539936</td>\n",
       "      <td>0.531999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.388600</td>\n",
       "      <td>1.335717</td>\n",
       "      <td>0.533046</td>\n",
       "      <td>0.527413</td>\n",
       "      <td>0.543488</td>\n",
       "      <td>0.533046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.372400</td>\n",
       "      <td>1.311416</td>\n",
       "      <td>0.546428</td>\n",
       "      <td>0.540091</td>\n",
       "      <td>0.549912</td>\n",
       "      <td>0.546428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.361000</td>\n",
       "      <td>1.348399</td>\n",
       "      <td>0.529148</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.545073</td>\n",
       "      <td>0.529148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.410300</td>\n",
       "      <td>1.323036</td>\n",
       "      <td>0.542239</td>\n",
       "      <td>0.531001</td>\n",
       "      <td>0.567511</td>\n",
       "      <td>0.542239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.388200</td>\n",
       "      <td>1.347263</td>\n",
       "      <td>0.527286</td>\n",
       "      <td>0.522664</td>\n",
       "      <td>0.576832</td>\n",
       "      <td>0.527286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.386800</td>\n",
       "      <td>1.324914</td>\n",
       "      <td>0.533628</td>\n",
       "      <td>0.531759</td>\n",
       "      <td>0.571241</td>\n",
       "      <td>0.533628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.319900</td>\n",
       "      <td>1.299320</td>\n",
       "      <td>0.545788</td>\n",
       "      <td>0.533140</td>\n",
       "      <td>0.593540</td>\n",
       "      <td>0.545788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.364200</td>\n",
       "      <td>1.264084</td>\n",
       "      <td>0.562020</td>\n",
       "      <td>0.560320</td>\n",
       "      <td>0.580553</td>\n",
       "      <td>0.562020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.300900</td>\n",
       "      <td>1.303220</td>\n",
       "      <td>0.550151</td>\n",
       "      <td>0.547227</td>\n",
       "      <td>0.566978</td>\n",
       "      <td>0.550151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.336600</td>\n",
       "      <td>1.279748</td>\n",
       "      <td>0.551955</td>\n",
       "      <td>0.542399</td>\n",
       "      <td>0.585931</td>\n",
       "      <td>0.551955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.326500</td>\n",
       "      <td>1.308272</td>\n",
       "      <td>0.537526</td>\n",
       "      <td>0.530170</td>\n",
       "      <td>0.603424</td>\n",
       "      <td>0.537526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.270900</td>\n",
       "      <td>1.255031</td>\n",
       "      <td>0.560449</td>\n",
       "      <td>0.553010</td>\n",
       "      <td>0.581592</td>\n",
       "      <td>0.560449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.347600</td>\n",
       "      <td>1.238273</td>\n",
       "      <td>0.574994</td>\n",
       "      <td>0.569818</td>\n",
       "      <td>0.586316</td>\n",
       "      <td>0.574994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.295500</td>\n",
       "      <td>1.243750</td>\n",
       "      <td>0.563475</td>\n",
       "      <td>0.559836</td>\n",
       "      <td>0.575883</td>\n",
       "      <td>0.563475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.309300</td>\n",
       "      <td>1.239636</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>0.562573</td>\n",
       "      <td>0.579102</td>\n",
       "      <td>0.568420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.286700</td>\n",
       "      <td>1.288627</td>\n",
       "      <td>0.558064</td>\n",
       "      <td>0.552873</td>\n",
       "      <td>0.585269</td>\n",
       "      <td>0.558064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.204000</td>\n",
       "      <td>1.258746</td>\n",
       "      <td>0.561555</td>\n",
       "      <td>0.554221</td>\n",
       "      <td>0.587768</td>\n",
       "      <td>0.561555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.229800</td>\n",
       "      <td>1.239995</td>\n",
       "      <td>0.571387</td>\n",
       "      <td>0.564353</td>\n",
       "      <td>0.581902</td>\n",
       "      <td>0.571387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.192000</td>\n",
       "      <td>1.229109</td>\n",
       "      <td>0.575751</td>\n",
       "      <td>0.570557</td>\n",
       "      <td>0.582489</td>\n",
       "      <td>0.575751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.350800</td>\n",
       "      <td>1.219911</td>\n",
       "      <td>0.572842</td>\n",
       "      <td>0.570941</td>\n",
       "      <td>0.582473</td>\n",
       "      <td>0.572842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.244600</td>\n",
       "      <td>1.251886</td>\n",
       "      <td>0.561904</td>\n",
       "      <td>0.557390</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.561904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.322900</td>\n",
       "      <td>1.264261</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.597617</td>\n",
       "      <td>0.561671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.297200</td>\n",
       "      <td>1.236193</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>0.576272</td>\n",
       "      <td>0.584748</td>\n",
       "      <td>0.580230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.284000</td>\n",
       "      <td>1.222667</td>\n",
       "      <td>0.578834</td>\n",
       "      <td>0.572916</td>\n",
       "      <td>0.600358</td>\n",
       "      <td>0.578834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.218300</td>\n",
       "      <td>1.272230</td>\n",
       "      <td>0.553235</td>\n",
       "      <td>0.551902</td>\n",
       "      <td>0.590706</td>\n",
       "      <td>0.553235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.280300</td>\n",
       "      <td>1.211348</td>\n",
       "      <td>0.583663</td>\n",
       "      <td>0.577196</td>\n",
       "      <td>0.603638</td>\n",
       "      <td>0.583663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.258600</td>\n",
       "      <td>1.237671</td>\n",
       "      <td>0.573423</td>\n",
       "      <td>0.569989</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.573423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.217200</td>\n",
       "      <td>1.234818</td>\n",
       "      <td>0.568362</td>\n",
       "      <td>0.564694</td>\n",
       "      <td>0.597370</td>\n",
       "      <td>0.568362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.237700</td>\n",
       "      <td>1.202353</td>\n",
       "      <td>0.584536</td>\n",
       "      <td>0.577814</td>\n",
       "      <td>0.599114</td>\n",
       "      <td>0.584536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.289600</td>\n",
       "      <td>1.229194</td>\n",
       "      <td>0.571387</td>\n",
       "      <td>0.570479</td>\n",
       "      <td>0.579385</td>\n",
       "      <td>0.571387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>1.188726</td>\n",
       "      <td>0.591285</td>\n",
       "      <td>0.589332</td>\n",
       "      <td>0.596036</td>\n",
       "      <td>0.591285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.208400</td>\n",
       "      <td>1.233315</td>\n",
       "      <td>0.572492</td>\n",
       "      <td>0.571496</td>\n",
       "      <td>0.589741</td>\n",
       "      <td>0.572492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.234900</td>\n",
       "      <td>1.198401</td>\n",
       "      <td>0.581859</td>\n",
       "      <td>0.578029</td>\n",
       "      <td>0.599092</td>\n",
       "      <td>0.581859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.265600</td>\n",
       "      <td>1.212626</td>\n",
       "      <td>0.583256</td>\n",
       "      <td>0.575169</td>\n",
       "      <td>0.611618</td>\n",
       "      <td>0.583256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.193600</td>\n",
       "      <td>1.190600</td>\n",
       "      <td>0.592099</td>\n",
       "      <td>0.586591</td>\n",
       "      <td>0.597057</td>\n",
       "      <td>0.592099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.178400</td>\n",
       "      <td>1.204008</td>\n",
       "      <td>0.580987</td>\n",
       "      <td>0.577037</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.580987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.208900</td>\n",
       "      <td>1.232438</td>\n",
       "      <td>0.581918</td>\n",
       "      <td>0.581641</td>\n",
       "      <td>0.590434</td>\n",
       "      <td>0.581918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.197400</td>\n",
       "      <td>1.204660</td>\n",
       "      <td>0.594543</td>\n",
       "      <td>0.587305</td>\n",
       "      <td>0.603897</td>\n",
       "      <td>0.594543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.193100</td>\n",
       "      <td>1.216655</td>\n",
       "      <td>0.581801</td>\n",
       "      <td>0.581788</td>\n",
       "      <td>0.595203</td>\n",
       "      <td>0.581801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.183800</td>\n",
       "      <td>1.209103</td>\n",
       "      <td>0.583547</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.594962</td>\n",
       "      <td>0.583547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.127300</td>\n",
       "      <td>1.226982</td>\n",
       "      <td>0.580754</td>\n",
       "      <td>0.568851</td>\n",
       "      <td>0.599779</td>\n",
       "      <td>0.580754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.233700</td>\n",
       "      <td>1.189497</td>\n",
       "      <td>0.585176</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.604499</td>\n",
       "      <td>0.585176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.219400</td>\n",
       "      <td>1.190071</td>\n",
       "      <td>0.586630</td>\n",
       "      <td>0.584918</td>\n",
       "      <td>0.603623</td>\n",
       "      <td>0.586630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.170400</td>\n",
       "      <td>1.186250</td>\n",
       "      <td>0.591226</td>\n",
       "      <td>0.587417</td>\n",
       "      <td>0.613162</td>\n",
       "      <td>0.591226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.222100</td>\n",
       "      <td>1.177999</td>\n",
       "      <td>0.587968</td>\n",
       "      <td>0.583165</td>\n",
       "      <td>0.614276</td>\n",
       "      <td>0.587968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.196900</td>\n",
       "      <td>1.164696</td>\n",
       "      <td>0.597684</td>\n",
       "      <td>0.593036</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>0.597684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.217500</td>\n",
       "      <td>1.168823</td>\n",
       "      <td>0.593786</td>\n",
       "      <td>0.589112</td>\n",
       "      <td>0.596855</td>\n",
       "      <td>0.593786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.172000</td>\n",
       "      <td>1.179264</td>\n",
       "      <td>0.594077</td>\n",
       "      <td>0.587327</td>\n",
       "      <td>0.611722</td>\n",
       "      <td>0.594077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.195300</td>\n",
       "      <td>1.161183</td>\n",
       "      <td>0.597044</td>\n",
       "      <td>0.597105</td>\n",
       "      <td>0.605738</td>\n",
       "      <td>0.597044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.161000</td>\n",
       "      <td>1.152725</td>\n",
       "      <td>0.597219</td>\n",
       "      <td>0.591451</td>\n",
       "      <td>0.602966</td>\n",
       "      <td>0.597219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.196900</td>\n",
       "      <td>1.192826</td>\n",
       "      <td>0.583139</td>\n",
       "      <td>0.585007</td>\n",
       "      <td>0.597169</td>\n",
       "      <td>0.583139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.200467</td>\n",
       "      <td>0.592099</td>\n",
       "      <td>0.587546</td>\n",
       "      <td>0.604077</td>\n",
       "      <td>0.592099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.179500</td>\n",
       "      <td>1.176816</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.587665</td>\n",
       "      <td>0.595141</td>\n",
       "      <td>0.586514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.048800</td>\n",
       "      <td>1.192820</td>\n",
       "      <td>0.601641</td>\n",
       "      <td>0.597515</td>\n",
       "      <td>0.604989</td>\n",
       "      <td>0.601641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.990300</td>\n",
       "      <td>1.220448</td>\n",
       "      <td>0.593205</td>\n",
       "      <td>0.591212</td>\n",
       "      <td>0.598278</td>\n",
       "      <td>0.593205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>1.185377</td>\n",
       "      <td>0.601175</td>\n",
       "      <td>0.601613</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>0.601175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.978800</td>\n",
       "      <td>1.204926</td>\n",
       "      <td>0.591343</td>\n",
       "      <td>0.590931</td>\n",
       "      <td>0.599216</td>\n",
       "      <td>0.591343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.965400</td>\n",
       "      <td>1.185533</td>\n",
       "      <td>0.603037</td>\n",
       "      <td>0.597965</td>\n",
       "      <td>0.614621</td>\n",
       "      <td>0.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.930900</td>\n",
       "      <td>1.207613</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.601629</td>\n",
       "      <td>0.607271</td>\n",
       "      <td>0.602804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.913400</td>\n",
       "      <td>1.225143</td>\n",
       "      <td>0.587677</td>\n",
       "      <td>0.589278</td>\n",
       "      <td>0.610662</td>\n",
       "      <td>0.587677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.003500</td>\n",
       "      <td>1.184717</td>\n",
       "      <td>0.598441</td>\n",
       "      <td>0.597410</td>\n",
       "      <td>0.599212</td>\n",
       "      <td>0.598441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>1.207213</td>\n",
       "      <td>0.603852</td>\n",
       "      <td>0.599424</td>\n",
       "      <td>0.607973</td>\n",
       "      <td>0.603852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.980900</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.607694</td>\n",
       "      <td>0.609011</td>\n",
       "      <td>0.609670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>1.051700</td>\n",
       "      <td>1.173388</td>\n",
       "      <td>0.594077</td>\n",
       "      <td>0.595422</td>\n",
       "      <td>0.609898</td>\n",
       "      <td>0.594077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>1.176547</td>\n",
       "      <td>0.597394</td>\n",
       "      <td>0.595793</td>\n",
       "      <td>0.598164</td>\n",
       "      <td>0.597394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>1.196575</td>\n",
       "      <td>0.604375</td>\n",
       "      <td>0.598813</td>\n",
       "      <td>0.607569</td>\n",
       "      <td>0.604375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>1.227239</td>\n",
       "      <td>0.589714</td>\n",
       "      <td>0.589714</td>\n",
       "      <td>0.611206</td>\n",
       "      <td>0.589714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>1.219824</td>\n",
       "      <td>0.595357</td>\n",
       "      <td>0.592930</td>\n",
       "      <td>0.607251</td>\n",
       "      <td>0.595357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>1.171821</td>\n",
       "      <td>0.602164</td>\n",
       "      <td>0.601893</td>\n",
       "      <td>0.604847</td>\n",
       "      <td>0.602164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1.249992</td>\n",
       "      <td>0.599255</td>\n",
       "      <td>0.600132</td>\n",
       "      <td>0.603683</td>\n",
       "      <td>0.599255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>1.161855</td>\n",
       "      <td>0.610484</td>\n",
       "      <td>0.607319</td>\n",
       "      <td>0.612694</td>\n",
       "      <td>0.610484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>1.211473</td>\n",
       "      <td>0.603153</td>\n",
       "      <td>0.599509</td>\n",
       "      <td>0.607067</td>\n",
       "      <td>0.603153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.964600</td>\n",
       "      <td>1.229690</td>\n",
       "      <td>0.591343</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.601876</td>\n",
       "      <td>0.591343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>1.022700</td>\n",
       "      <td>1.185638</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.599973</td>\n",
       "      <td>0.605815</td>\n",
       "      <td>0.602630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.943700</td>\n",
       "      <td>1.187545</td>\n",
       "      <td>0.600244</td>\n",
       "      <td>0.599458</td>\n",
       "      <td>0.611651</td>\n",
       "      <td>0.600244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.971500</td>\n",
       "      <td>1.181989</td>\n",
       "      <td>0.603502</td>\n",
       "      <td>0.602736</td>\n",
       "      <td>0.605458</td>\n",
       "      <td>0.603502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>1.229061</td>\n",
       "      <td>0.585408</td>\n",
       "      <td>0.586706</td>\n",
       "      <td>0.601383</td>\n",
       "      <td>0.585408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.590703</td>\n",
       "      <td>0.593053</td>\n",
       "      <td>0.606925</td>\n",
       "      <td>0.590703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>1.210475</td>\n",
       "      <td>0.595125</td>\n",
       "      <td>0.594730</td>\n",
       "      <td>0.604197</td>\n",
       "      <td>0.595125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.943500</td>\n",
       "      <td>1.189828</td>\n",
       "      <td>0.603270</td>\n",
       "      <td>0.600926</td>\n",
       "      <td>0.607168</td>\n",
       "      <td>0.603270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.964900</td>\n",
       "      <td>1.185691</td>\n",
       "      <td>0.603968</td>\n",
       "      <td>0.602912</td>\n",
       "      <td>0.611051</td>\n",
       "      <td>0.603968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.992300</td>\n",
       "      <td>1.197255</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.603655</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>0.606470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>1.154099</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>0.609088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>1.166509</td>\n",
       "      <td>0.604317</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>0.607812</td>\n",
       "      <td>0.604317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.956600</td>\n",
       "      <td>1.181711</td>\n",
       "      <td>0.597626</td>\n",
       "      <td>0.592985</td>\n",
       "      <td>0.615493</td>\n",
       "      <td>0.597626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>1.168265</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.605260</td>\n",
       "      <td>0.614041</td>\n",
       "      <td>0.604433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.950100</td>\n",
       "      <td>1.194931</td>\n",
       "      <td>0.602455</td>\n",
       "      <td>0.602197</td>\n",
       "      <td>0.604081</td>\n",
       "      <td>0.602455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>1.202318</td>\n",
       "      <td>0.607691</td>\n",
       "      <td>0.602581</td>\n",
       "      <td>0.609998</td>\n",
       "      <td>0.607691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>1.195202</td>\n",
       "      <td>0.599255</td>\n",
       "      <td>0.596726</td>\n",
       "      <td>0.602886</td>\n",
       "      <td>0.599255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.893600</td>\n",
       "      <td>1.197746</td>\n",
       "      <td>0.600768</td>\n",
       "      <td>0.596629</td>\n",
       "      <td>0.610428</td>\n",
       "      <td>0.600768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.988700</td>\n",
       "      <td>1.198454</td>\n",
       "      <td>0.597626</td>\n",
       "      <td>0.596037</td>\n",
       "      <td>0.600191</td>\n",
       "      <td>0.597626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.941100</td>\n",
       "      <td>1.183722</td>\n",
       "      <td>0.601815</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>0.615934</td>\n",
       "      <td>0.601815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>1.178706</td>\n",
       "      <td>0.606121</td>\n",
       "      <td>0.602051</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>0.606121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.919300</td>\n",
       "      <td>1.188029</td>\n",
       "      <td>0.601932</td>\n",
       "      <td>0.601857</td>\n",
       "      <td>0.612631</td>\n",
       "      <td>0.601932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.939900</td>\n",
       "      <td>1.170180</td>\n",
       "      <td>0.611008</td>\n",
       "      <td>0.607071</td>\n",
       "      <td>0.611071</td>\n",
       "      <td>0.611008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.902100</td>\n",
       "      <td>1.172673</td>\n",
       "      <td>0.609030</td>\n",
       "      <td>0.608944</td>\n",
       "      <td>0.610787</td>\n",
       "      <td>0.609030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>1.188946</td>\n",
       "      <td>0.599546</td>\n",
       "      <td>0.602728</td>\n",
       "      <td>0.618154</td>\n",
       "      <td>0.599546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>1.186835</td>\n",
       "      <td>0.606993</td>\n",
       "      <td>0.606593</td>\n",
       "      <td>0.619900</td>\n",
       "      <td>0.606993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>1.185971</td>\n",
       "      <td>0.600710</td>\n",
       "      <td>0.602158</td>\n",
       "      <td>0.608560</td>\n",
       "      <td>0.600710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.965900</td>\n",
       "      <td>1.154465</td>\n",
       "      <td>0.608680</td>\n",
       "      <td>0.606954</td>\n",
       "      <td>0.615150</td>\n",
       "      <td>0.608680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>1.163587</td>\n",
       "      <td>0.617466</td>\n",
       "      <td>0.614191</td>\n",
       "      <td>0.623875</td>\n",
       "      <td>0.617466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.184126</td>\n",
       "      <td>0.614615</td>\n",
       "      <td>0.611631</td>\n",
       "      <td>0.615978</td>\n",
       "      <td>0.614615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>1.152592</td>\n",
       "      <td>0.614557</td>\n",
       "      <td>0.612443</td>\n",
       "      <td>0.614398</td>\n",
       "      <td>0.614557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>1.160553</td>\n",
       "      <td>0.603328</td>\n",
       "      <td>0.601619</td>\n",
       "      <td>0.615097</td>\n",
       "      <td>0.603328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.916600</td>\n",
       "      <td>1.181657</td>\n",
       "      <td>0.606993</td>\n",
       "      <td>0.609490</td>\n",
       "      <td>0.618616</td>\n",
       "      <td>0.606993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>1.171225</td>\n",
       "      <td>0.610368</td>\n",
       "      <td>0.609268</td>\n",
       "      <td>0.615404</td>\n",
       "      <td>0.610368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.945300</td>\n",
       "      <td>1.147204</td>\n",
       "      <td>0.606819</td>\n",
       "      <td>0.604542</td>\n",
       "      <td>0.617349</td>\n",
       "      <td>0.606819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>0.949600</td>\n",
       "      <td>1.142311</td>\n",
       "      <td>0.613975</td>\n",
       "      <td>0.613212</td>\n",
       "      <td>0.620401</td>\n",
       "      <td>0.613975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.952600</td>\n",
       "      <td>1.185001</td>\n",
       "      <td>0.600303</td>\n",
       "      <td>0.602195</td>\n",
       "      <td>0.611694</td>\n",
       "      <td>0.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>0.939400</td>\n",
       "      <td>1.158194</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.608810</td>\n",
       "      <td>0.615204</td>\n",
       "      <td>0.609670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.926800</td>\n",
       "      <td>1.162127</td>\n",
       "      <td>0.609320</td>\n",
       "      <td>0.607074</td>\n",
       "      <td>0.619332</td>\n",
       "      <td>0.609320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>0.879200</td>\n",
       "      <td>1.154480</td>\n",
       "      <td>0.609146</td>\n",
       "      <td>0.608239</td>\n",
       "      <td>0.612844</td>\n",
       "      <td>0.609146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>1.163735</td>\n",
       "      <td>0.613509</td>\n",
       "      <td>0.612326</td>\n",
       "      <td>0.622008</td>\n",
       "      <td>0.613509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>1.157208</td>\n",
       "      <td>0.611299</td>\n",
       "      <td>0.611082</td>\n",
       "      <td>0.615061</td>\n",
       "      <td>0.611299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>1.172547</td>\n",
       "      <td>0.606528</td>\n",
       "      <td>0.605783</td>\n",
       "      <td>0.614924</td>\n",
       "      <td>0.606528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>1.143225</td>\n",
       "      <td>0.613219</td>\n",
       "      <td>0.613777</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.613219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.915800</td>\n",
       "      <td>1.146953</td>\n",
       "      <td>0.616302</td>\n",
       "      <td>0.614858</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>0.616302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>0.850500</td>\n",
       "      <td>1.163967</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>0.612507</td>\n",
       "      <td>0.617573</td>\n",
       "      <td>0.615255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>1.290470</td>\n",
       "      <td>0.604957</td>\n",
       "      <td>0.605409</td>\n",
       "      <td>0.613800</td>\n",
       "      <td>0.604957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>1.258798</td>\n",
       "      <td>0.613219</td>\n",
       "      <td>0.612634</td>\n",
       "      <td>0.616366</td>\n",
       "      <td>0.613219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>1.268893</td>\n",
       "      <td>0.612753</td>\n",
       "      <td>0.610690</td>\n",
       "      <td>0.613288</td>\n",
       "      <td>0.612753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>0.587300</td>\n",
       "      <td>1.284494</td>\n",
       "      <td>0.609902</td>\n",
       "      <td>0.609947</td>\n",
       "      <td>0.611199</td>\n",
       "      <td>0.609902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>1.317357</td>\n",
       "      <td>0.610717</td>\n",
       "      <td>0.608452</td>\n",
       "      <td>0.610646</td>\n",
       "      <td>0.610717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>1.258672</td>\n",
       "      <td>0.607459</td>\n",
       "      <td>0.607471</td>\n",
       "      <td>0.609876</td>\n",
       "      <td>0.607459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>1.294020</td>\n",
       "      <td>0.606877</td>\n",
       "      <td>0.606566</td>\n",
       "      <td>0.611008</td>\n",
       "      <td>0.606877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>1.345386</td>\n",
       "      <td>0.592797</td>\n",
       "      <td>0.594788</td>\n",
       "      <td>0.604691</td>\n",
       "      <td>0.592797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>1.302853</td>\n",
       "      <td>0.605015</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.607794</td>\n",
       "      <td>0.605015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>0.613400</td>\n",
       "      <td>1.308558</td>\n",
       "      <td>0.607226</td>\n",
       "      <td>0.607106</td>\n",
       "      <td>0.612003</td>\n",
       "      <td>0.607226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.552800</td>\n",
       "      <td>1.332190</td>\n",
       "      <td>0.601990</td>\n",
       "      <td>0.603047</td>\n",
       "      <td>0.608148</td>\n",
       "      <td>0.601990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>1.346019</td>\n",
       "      <td>0.606411</td>\n",
       "      <td>0.606295</td>\n",
       "      <td>0.606784</td>\n",
       "      <td>0.606411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>1.339579</td>\n",
       "      <td>0.605248</td>\n",
       "      <td>0.604757</td>\n",
       "      <td>0.606133</td>\n",
       "      <td>0.605248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>1.361614</td>\n",
       "      <td>0.605888</td>\n",
       "      <td>0.604185</td>\n",
       "      <td>0.609554</td>\n",
       "      <td>0.605888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.611100</td>\n",
       "      <td>1.348056</td>\n",
       "      <td>0.597568</td>\n",
       "      <td>0.596958</td>\n",
       "      <td>0.602593</td>\n",
       "      <td>0.597568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>1.362144</td>\n",
       "      <td>0.605131</td>\n",
       "      <td>0.604204</td>\n",
       "      <td>0.612462</td>\n",
       "      <td>0.605131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>1.352512</td>\n",
       "      <td>0.605713</td>\n",
       "      <td>0.604152</td>\n",
       "      <td>0.608423</td>\n",
       "      <td>0.605713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>1.352124</td>\n",
       "      <td>0.607750</td>\n",
       "      <td>0.606326</td>\n",
       "      <td>0.607393</td>\n",
       "      <td>0.607750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>1.342514</td>\n",
       "      <td>0.609437</td>\n",
       "      <td>0.605076</td>\n",
       "      <td>0.610349</td>\n",
       "      <td>0.609437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>1.311436</td>\n",
       "      <td>0.608971</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.610016</td>\n",
       "      <td>0.608971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.540100</td>\n",
       "      <td>1.331514</td>\n",
       "      <td>0.608273</td>\n",
       "      <td>0.606820</td>\n",
       "      <td>0.610999</td>\n",
       "      <td>0.608273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>0.673900</td>\n",
       "      <td>1.316243</td>\n",
       "      <td>0.607982</td>\n",
       "      <td>0.608325</td>\n",
       "      <td>0.611014</td>\n",
       "      <td>0.607982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>1.306822</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.609807</td>\n",
       "      <td>0.613110</td>\n",
       "      <td>0.609204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>0.609400</td>\n",
       "      <td>1.333444</td>\n",
       "      <td>0.605830</td>\n",
       "      <td>0.605687</td>\n",
       "      <td>0.609764</td>\n",
       "      <td>0.605830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>1.406100</td>\n",
       "      <td>0.606644</td>\n",
       "      <td>0.605522</td>\n",
       "      <td>0.609852</td>\n",
       "      <td>0.606644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.573100</td>\n",
       "      <td>1.367049</td>\n",
       "      <td>0.605539</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>0.610124</td>\n",
       "      <td>0.605539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>1.328444</td>\n",
       "      <td>0.601932</td>\n",
       "      <td>0.602780</td>\n",
       "      <td>0.606596</td>\n",
       "      <td>0.601932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7850</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>1.315909</td>\n",
       "      <td>0.610600</td>\n",
       "      <td>0.609249</td>\n",
       "      <td>0.609316</td>\n",
       "      <td>0.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.611100</td>\n",
       "      <td>1.328997</td>\n",
       "      <td>0.601466</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.606534</td>\n",
       "      <td>0.601466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>1.349000</td>\n",
       "      <td>0.601350</td>\n",
       "      <td>0.603981</td>\n",
       "      <td>0.614605</td>\n",
       "      <td>0.601350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>1.354346</td>\n",
       "      <td>0.608622</td>\n",
       "      <td>0.607021</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.608622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8050</td>\n",
       "      <td>0.586900</td>\n",
       "      <td>1.326347</td>\n",
       "      <td>0.604666</td>\n",
       "      <td>0.605034</td>\n",
       "      <td>0.610498</td>\n",
       "      <td>0.604666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>1.360754</td>\n",
       "      <td>0.600884</td>\n",
       "      <td>0.599868</td>\n",
       "      <td>0.604452</td>\n",
       "      <td>0.600884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8150</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>1.330226</td>\n",
       "      <td>0.607750</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.609933</td>\n",
       "      <td>0.607750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.630500</td>\n",
       "      <td>1.291889</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>0.615350</td>\n",
       "      <td>0.616253</td>\n",
       "      <td>0.617582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.593100</td>\n",
       "      <td>1.318550</td>\n",
       "      <td>0.614673</td>\n",
       "      <td>0.613465</td>\n",
       "      <td>0.617666</td>\n",
       "      <td>0.614673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>1.328686</td>\n",
       "      <td>0.607284</td>\n",
       "      <td>0.607176</td>\n",
       "      <td>0.609934</td>\n",
       "      <td>0.607284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>1.334926</td>\n",
       "      <td>0.610542</td>\n",
       "      <td>0.611432</td>\n",
       "      <td>0.614998</td>\n",
       "      <td>0.610542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>1.310881</td>\n",
       "      <td>0.617175</td>\n",
       "      <td>0.616471</td>\n",
       "      <td>0.619449</td>\n",
       "      <td>0.617175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8450</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>1.331013</td>\n",
       "      <td>0.606179</td>\n",
       "      <td>0.605362</td>\n",
       "      <td>0.612037</td>\n",
       "      <td>0.606179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>1.298090</td>\n",
       "      <td>0.614091</td>\n",
       "      <td>0.612770</td>\n",
       "      <td>0.616590</td>\n",
       "      <td>0.614091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8550</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>1.351516</td>\n",
       "      <td>0.610717</td>\n",
       "      <td>0.610799</td>\n",
       "      <td>0.614720</td>\n",
       "      <td>0.610717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.604700</td>\n",
       "      <td>1.341082</td>\n",
       "      <td>0.614615</td>\n",
       "      <td>0.612353</td>\n",
       "      <td>0.616652</td>\n",
       "      <td>0.614615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8650</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>1.364022</td>\n",
       "      <td>0.605655</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>0.611017</td>\n",
       "      <td>0.605655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>1.331243</td>\n",
       "      <td>0.603037</td>\n",
       "      <td>0.603910</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>0.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>1.350326</td>\n",
       "      <td>0.606121</td>\n",
       "      <td>0.606820</td>\n",
       "      <td>0.611783</td>\n",
       "      <td>0.606121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.673900</td>\n",
       "      <td>1.298999</td>\n",
       "      <td>0.612288</td>\n",
       "      <td>0.612556</td>\n",
       "      <td>0.615286</td>\n",
       "      <td>0.612288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8850</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>1.307371</td>\n",
       "      <td>0.613800</td>\n",
       "      <td>0.612573</td>\n",
       "      <td>0.613594</td>\n",
       "      <td>0.613800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.582900</td>\n",
       "      <td>1.330821</td>\n",
       "      <td>0.613160</td>\n",
       "      <td>0.613074</td>\n",
       "      <td>0.617040</td>\n",
       "      <td>0.613160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8950</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>1.311864</td>\n",
       "      <td>0.615895</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>0.614577</td>\n",
       "      <td>0.615895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>1.337771</td>\n",
       "      <td>0.617466</td>\n",
       "      <td>0.614024</td>\n",
       "      <td>0.618464</td>\n",
       "      <td>0.617466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9050</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>1.330552</td>\n",
       "      <td>0.608215</td>\n",
       "      <td>0.608707</td>\n",
       "      <td>0.615490</td>\n",
       "      <td>0.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>1.303761</td>\n",
       "      <td>0.617466</td>\n",
       "      <td>0.615975</td>\n",
       "      <td>0.616701</td>\n",
       "      <td>0.617466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9150</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>1.322283</td>\n",
       "      <td>0.613393</td>\n",
       "      <td>0.613409</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.613393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.584500</td>\n",
       "      <td>1.333172</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.604626</td>\n",
       "      <td>0.607043</td>\n",
       "      <td>0.604433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.380628</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.609123</td>\n",
       "      <td>0.610912</td>\n",
       "      <td>0.609088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>1.368757</td>\n",
       "      <td>0.611648</td>\n",
       "      <td>0.610507</td>\n",
       "      <td>0.615164</td>\n",
       "      <td>0.611648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9350</td>\n",
       "      <td>0.636800</td>\n",
       "      <td>1.329691</td>\n",
       "      <td>0.606935</td>\n",
       "      <td>0.606952</td>\n",
       "      <td>0.611786</td>\n",
       "      <td>0.606935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>1.349938</td>\n",
       "      <td>0.610949</td>\n",
       "      <td>0.609990</td>\n",
       "      <td>0.610447</td>\n",
       "      <td>0.610949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>0.573900</td>\n",
       "      <td>1.347803</td>\n",
       "      <td>0.604782</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.607503</td>\n",
       "      <td>0.604782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>1.344728</td>\n",
       "      <td>0.605539</td>\n",
       "      <td>0.607184</td>\n",
       "      <td>0.612711</td>\n",
       "      <td>0.605539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9550</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>1.338825</td>\n",
       "      <td>0.610019</td>\n",
       "      <td>0.608603</td>\n",
       "      <td>0.611873</td>\n",
       "      <td>0.610019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.598900</td>\n",
       "      <td>1.344222</td>\n",
       "      <td>0.611706</td>\n",
       "      <td>0.612182</td>\n",
       "      <td>0.617577</td>\n",
       "      <td>0.611706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9650</td>\n",
       "      <td>0.616700</td>\n",
       "      <td>1.330408</td>\n",
       "      <td>0.609320</td>\n",
       "      <td>0.609231</td>\n",
       "      <td>0.614086</td>\n",
       "      <td>0.609320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>1.388913</td>\n",
       "      <td>0.611415</td>\n",
       "      <td>0.611019</td>\n",
       "      <td>0.612942</td>\n",
       "      <td>0.611415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>1.465715</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.609868</td>\n",
       "      <td>0.612841</td>\n",
       "      <td>0.609670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>1.487741</td>\n",
       "      <td>0.612171</td>\n",
       "      <td>0.610501</td>\n",
       "      <td>0.610252</td>\n",
       "      <td>0.612171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9850</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>1.525618</td>\n",
       "      <td>0.605481</td>\n",
       "      <td>0.604794</td>\n",
       "      <td>0.609026</td>\n",
       "      <td>0.605481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>1.516206</td>\n",
       "      <td>0.604957</td>\n",
       "      <td>0.603898</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>0.604957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9950</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>1.522109</td>\n",
       "      <td>0.606528</td>\n",
       "      <td>0.605021</td>\n",
       "      <td>0.606185</td>\n",
       "      <td>0.606528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>1.553218</td>\n",
       "      <td>0.601699</td>\n",
       "      <td>0.600266</td>\n",
       "      <td>0.603764</td>\n",
       "      <td>0.601699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10050</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>1.534986</td>\n",
       "      <td>0.606237</td>\n",
       "      <td>0.605114</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>0.606237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>1.552752</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.605128</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.606470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10150</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>1.546205</td>\n",
       "      <td>0.603153</td>\n",
       "      <td>0.603963</td>\n",
       "      <td>0.605452</td>\n",
       "      <td>0.603153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>1.554792</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>0.606883</td>\n",
       "      <td>0.604433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>1.576669</td>\n",
       "      <td>0.608390</td>\n",
       "      <td>0.608097</td>\n",
       "      <td>0.608478</td>\n",
       "      <td>0.608390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>1.590355</td>\n",
       "      <td>0.607342</td>\n",
       "      <td>0.607031</td>\n",
       "      <td>0.608860</td>\n",
       "      <td>0.607342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10350</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>1.597760</td>\n",
       "      <td>0.601350</td>\n",
       "      <td>0.602123</td>\n",
       "      <td>0.605989</td>\n",
       "      <td>0.601350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>1.591070</td>\n",
       "      <td>0.608564</td>\n",
       "      <td>0.608051</td>\n",
       "      <td>0.607893</td>\n",
       "      <td>0.608564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10450</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>1.593999</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.608374</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.609088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>1.606082</td>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>0.607539</td>\n",
       "      <td>0.603561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>1.606715</td>\n",
       "      <td>0.604084</td>\n",
       "      <td>0.604499</td>\n",
       "      <td>0.606347</td>\n",
       "      <td>0.604084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>1.586115</td>\n",
       "      <td>0.606004</td>\n",
       "      <td>0.604962</td>\n",
       "      <td>0.605895</td>\n",
       "      <td>0.606004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10650</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>1.622738</td>\n",
       "      <td>0.599663</td>\n",
       "      <td>0.599944</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.599663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>1.597962</td>\n",
       "      <td>0.606935</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>0.606935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.289200</td>\n",
       "      <td>1.639140</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.604883</td>\n",
       "      <td>0.607397</td>\n",
       "      <td>0.604433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>1.622670</td>\n",
       "      <td>0.606121</td>\n",
       "      <td>0.605117</td>\n",
       "      <td>0.606575</td>\n",
       "      <td>0.606121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10850</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>1.624203</td>\n",
       "      <td>0.609553</td>\n",
       "      <td>0.607534</td>\n",
       "      <td>0.609999</td>\n",
       "      <td>0.609553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>1.663282</td>\n",
       "      <td>0.607633</td>\n",
       "      <td>0.606039</td>\n",
       "      <td>0.608787</td>\n",
       "      <td>0.607633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10950</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>1.658035</td>\n",
       "      <td>0.603677</td>\n",
       "      <td>0.604755</td>\n",
       "      <td>0.607007</td>\n",
       "      <td>0.603677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>1.651446</td>\n",
       "      <td>0.608040</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>0.608040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11050</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>1.666703</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.608290</td>\n",
       "      <td>0.608807</td>\n",
       "      <td>0.609204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>1.665313</td>\n",
       "      <td>0.606528</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>0.608058</td>\n",
       "      <td>0.606528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11150</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>1.670877</td>\n",
       "      <td>0.610659</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.611074</td>\n",
       "      <td>0.610659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.300200</td>\n",
       "      <td>1.676669</td>\n",
       "      <td>0.607459</td>\n",
       "      <td>0.606675</td>\n",
       "      <td>0.610051</td>\n",
       "      <td>0.607459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>1.649596</td>\n",
       "      <td>0.607575</td>\n",
       "      <td>0.606843</td>\n",
       "      <td>0.607819</td>\n",
       "      <td>0.607575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>1.649301</td>\n",
       "      <td>0.608797</td>\n",
       "      <td>0.608686</td>\n",
       "      <td>0.609938</td>\n",
       "      <td>0.608797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11350</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>1.632765</td>\n",
       "      <td>0.604026</td>\n",
       "      <td>0.603594</td>\n",
       "      <td>0.604358</td>\n",
       "      <td>0.604026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>1.628082</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>0.605269</td>\n",
       "      <td>0.604433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11450</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>1.640266</td>\n",
       "      <td>0.604084</td>\n",
       "      <td>0.603335</td>\n",
       "      <td>0.603811</td>\n",
       "      <td>0.604084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>1.631704</td>\n",
       "      <td>0.606993</td>\n",
       "      <td>0.606411</td>\n",
       "      <td>0.607644</td>\n",
       "      <td>0.606993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11550</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>1.627539</td>\n",
       "      <td>0.606935</td>\n",
       "      <td>0.606038</td>\n",
       "      <td>0.606285</td>\n",
       "      <td>0.606935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1.633348</td>\n",
       "      <td>0.606877</td>\n",
       "      <td>0.607126</td>\n",
       "      <td>0.608475</td>\n",
       "      <td>0.606877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11650</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>1.633886</td>\n",
       "      <td>0.607866</td>\n",
       "      <td>0.607442</td>\n",
       "      <td>0.608144</td>\n",
       "      <td>0.607866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>1.640189</td>\n",
       "      <td>0.603735</td>\n",
       "      <td>0.604145</td>\n",
       "      <td>0.606422</td>\n",
       "      <td>0.603735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>1.643214</td>\n",
       "      <td>0.604724</td>\n",
       "      <td>0.605004</td>\n",
       "      <td>0.606920</td>\n",
       "      <td>0.604724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>1.655189</td>\n",
       "      <td>0.604608</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>0.608140</td>\n",
       "      <td>0.604608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11850</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>1.664741</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>0.608706</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.609670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>1.674167</td>\n",
       "      <td>0.609611</td>\n",
       "      <td>0.609060</td>\n",
       "      <td>0.610494</td>\n",
       "      <td>0.609611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11950</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>1.659849</td>\n",
       "      <td>0.608564</td>\n",
       "      <td>0.607534</td>\n",
       "      <td>0.607635</td>\n",
       "      <td>0.608564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>1.664969</td>\n",
       "      <td>0.605713</td>\n",
       "      <td>0.605381</td>\n",
       "      <td>0.605830</td>\n",
       "      <td>0.605713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12050</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>1.666195</td>\n",
       "      <td>0.605597</td>\n",
       "      <td>0.603656</td>\n",
       "      <td>0.605605</td>\n",
       "      <td>0.605597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>1.651382</td>\n",
       "      <td>0.603619</td>\n",
       "      <td>0.603409</td>\n",
       "      <td>0.603579</td>\n",
       "      <td>0.603619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12150</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>1.653330</td>\n",
       "      <td>0.605073</td>\n",
       "      <td>0.604951</td>\n",
       "      <td>0.605880</td>\n",
       "      <td>0.605073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>1.647513</td>\n",
       "      <td>0.605481</td>\n",
       "      <td>0.605700</td>\n",
       "      <td>0.607042</td>\n",
       "      <td>0.605481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>1.645505</td>\n",
       "      <td>0.603386</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>0.605108</td>\n",
       "      <td>0.603386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>1.648572</td>\n",
       "      <td>0.605248</td>\n",
       "      <td>0.605206</td>\n",
       "      <td>0.606078</td>\n",
       "      <td>0.605248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12350</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>1.643036</td>\n",
       "      <td>0.606761</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.606573</td>\n",
       "      <td>0.606761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>1.642277</td>\n",
       "      <td>0.604492</td>\n",
       "      <td>0.604506</td>\n",
       "      <td>0.604694</td>\n",
       "      <td>0.604492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12450</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>1.644444</td>\n",
       "      <td>0.606761</td>\n",
       "      <td>0.606195</td>\n",
       "      <td>0.606474</td>\n",
       "      <td>0.606761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>1.640116</td>\n",
       "      <td>0.607808</td>\n",
       "      <td>0.607193</td>\n",
       "      <td>0.607638</td>\n",
       "      <td>0.607808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12550</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>1.635550</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.605893</td>\n",
       "      <td>0.605850</td>\n",
       "      <td>0.606470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>1.634378</td>\n",
       "      <td>0.606702</td>\n",
       "      <td>0.606516</td>\n",
       "      <td>0.607114</td>\n",
       "      <td>0.606702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12650</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>1.635136</td>\n",
       "      <td>0.606295</td>\n",
       "      <td>0.605978</td>\n",
       "      <td>0.606329</td>\n",
       "      <td>0.606295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>1.635320</td>\n",
       "      <td>0.606935</td>\n",
       "      <td>0.606366</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.606935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>1.636833</td>\n",
       "      <td>0.606819</td>\n",
       "      <td>0.606308</td>\n",
       "      <td>0.606637</td>\n",
       "      <td>0.606819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>1.638764</td>\n",
       "      <td>0.606411</td>\n",
       "      <td>0.605962</td>\n",
       "      <td>0.606528</td>\n",
       "      <td>0.606411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12850</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>1.639362</td>\n",
       "      <td>0.606702</td>\n",
       "      <td>0.606308</td>\n",
       "      <td>0.607013</td>\n",
       "      <td>0.606702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "Configuration saved in ./results/checkpoint-10500/config.json\n",
      "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "Configuration saved in ./results/checkpoint-11000/config.json\n",
      "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-11500\n",
      "Configuration saved in ./results/checkpoint-11500/config.json\n",
      "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-12000\n",
      "Configuration saved in ./results/checkpoint-12000/config.json\n",
      "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-11500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-12500\n",
      "Configuration saved in ./results/checkpoint-12500/config.json\n",
      "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12892, training_loss=0.796463491603746, metrics={'train_runtime': 8566.2152, 'train_samples_per_second': 24.077, 'train_steps_per_second': 1.505, 'total_flos': 1.1765360958244992e+16, 'train_loss': 0.796463491603746, 'epoch': 4.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.\n",
    "    dataloader_pin_memory=False,  # Whether you want to pin memory in data loaders or not. Will default to True\n",
    "    # evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    logging_dir='./logs'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics  # The function that will be used to compute metrics at evaluation\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 17188\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='269' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [269/269 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6394577026367188,\n",
       " 'eval_accuracy': 0.6062950895973935,\n",
       " 'eval_f1': 0.6059304137567896,\n",
       " 'eval_precision': 0.6066650551917165,\n",
       " 'eval_recall': 0.6062950895973935,\n",
       " 'eval_runtime': 28.2961,\n",
       " 'eval_samples_per_second': 607.433,\n",
       " 'eval_steps_per_second': 9.507,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./JEmpatheticDialogues_WRIME_not_same_labels_num/tokenizer_config.json\n",
      "Special tokens file saved in ./JEmpatheticDialogues_WRIME_not_same_labels_num/special_tokens_map.json\n",
      "Configuration saved in ./JEmpatheticDialogues_WRIME_not_same_labels_num/config.json\n",
      "Model weights saved in ./JEmpatheticDialogues_WRIME_not_same_labels_num/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"./JEmpatheticDialogues_WRIME_not_same_labels_num\"\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd9c66b3ad3c2d6d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd9c66b3ad3c2d6d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --host localhost --port 8888"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
